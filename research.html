<!DOCTYPE html>
<html>
<head profile="http://www.w3.org/2005/10/profile">
    <link rel="icon" 
          type="image/png" 
          href="./img/favicon.webp">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Radi's Portfolio</title>
<link rel="stylesheet" href="./stylesheet.css">
</head>
<body>

<div class="sidenav">
    <div class="navblock">
        <div class="navblock_text">
            <a href="./index.html">About</a>
            
            <a style="color:#3498DB" href="./research.html">Research</a>
            <a href="./portfolio.html">Portfolio</a>
            <a href="./resume.html">Resume</a>

        </div>
    </div>

</div>

<div class="main">
  <h2>Research Activity</h2>
    <p>My research work is focused on different avenues of Computer Vision, including Image Restoration, 3D Image Reconstruction, and Medical Image Analysis. In the past, I was involved in Cyber Secutiy related research work.</p>

    <br>


  <h3 class="research_accent">Publications</h3>

    <h4>"Blind Image Deblurring with FFT-ReLU Sparsity Prior"</h4>
        <p><i>AMA Radi, PS Majumder, MM Khan, IEEE/CVF Winter Conference on Applications of Computer Vision </i></p>
        <p>Blind image deblurring is the process of recovering a sharp image from a blurred one without prior knowledge about the blur kernel. It is a small data problem, since the key challenge lies in estimating the unknown degrees of blur from a single image or limited data, instead of learning from large datasets. The solution depends heavily on developing algorithms that effectively model the image degradation process. We introduce a method that leverages a prior which targets the blur kernel to achieve effective deblurring across a wide range of image types. In our extensive empirical analysis, our algorithm achieves results that are competitive with the state-of-the-art blind image deblurring algorithms, and it offers up to two times faster inference, making it a highly efficient solution.</p>
        <p><a href="https://arxiv.org/pdf/2406.08344" target="_blank">Download Preprint</a></p>
        <br>

    <h4>"An end-to-end authentication mechanism for wireless body area networks"</h4>
        <p><i>M Jahan, FT Zohra, MK Parvez, U Kabir, AM Al Radi, S Kabir Smart Health 29, 100413</i></p>
        <p>Wireless Body Area Network (WBAN) ensures high
quality healthcare services by endowing distant and continual
 monitoring of patients’ health conditions. The security and
 privacy of the sensitive health-related data transmitted through
 the WBAN should be preserved to maximize its benefits. In this
 regard, user authentication is one of the primary mechanisms
 to protect health data that verifies the identities of entities
 involved in the communication process. Since WBAN carries
 crucial health data, every entity engaged in the data transfer
 process must be authenticated. In literature, an end-to-end user
 authentication mechanism covering each communicating party
 is absent. Besides, most of the existing user authentication
 mechanisms are designed assuming that the patient’s mobile
 phone is trusted. In reality, a patient’s mobile phone can be stolen
 or comprised by malware and thus behaves maliciously. Our
 work addresses these drawbacks and proposes an end-to-end user
 authentication and session key agreement scheme between sensor
 nodes and medical experts in a scenario where the patient’s
 mobile phone is semi-trusted. We present a formal security
 analysis using BAN logic. Besides, we also provide an informal
 security analysis of the proposed scheme. Both studies indicate
 that our method is robust against well-known security attacks.
 In addition, our scheme achieves comparable computation and
 communication costs concerning the related existing works. The
 simulation shows that our method preserves satisfactory network
 performance.</p>
        <p><a href="https://arxiv.org/pdf/2004.12438.pdf" target="_blank">Download</a></p>
        <br>

        <h4>"Vision Transformer and FFT-ReLU Fusion for Advanced Image Deblurring"</h4>
        <p><i>Syed Mumtahin Mahmud, Mahdi Mohd Hossain Noki, Prothito Shovon Majumder, Abdul Mohaimen Al Radi, Md Haider Ali, Md Mosaddek Khan </i></p>
        <p>Image deblurring is a crucial task in computer vision, aiming to recover sharp
 images from blurry inputs caused by camera shake, motion blur, or other factors.
 Traditional methods often struggle with complex or severe blur, particularly in
 high-resolution images. Recent advancements in deep learning, particularly Con
volutional Neural Networks (CNNs) and Vision Transformers (ViTs), have shown
 promise but have limitations in capturing long-range dependencies and compu
tational efficiency. In this paper, we propose a novel image deblurring approach
 that integrates the strengths of Vision Transformers and the Fast Fourier Trans
form (FFT) with ReLU (Rectified Linear Unit) sparsity. Our method leverages a
 Vision Transformer architecture designed for image restoration tasks to prepro
cess blurry images, efficiently capturing both local and global features to reduce
 blurriness. This is followed by post-processing using FFT with ReLU sparsity,
 which targets and removes blur-related frequencies while preserving image sharp
ness and clarity. Extensive experiments on benchmark datasets demonstrate that
 our method produces sharper, more visually appealing images compared to state
of-the-art models. Furthermore, subjective human evaluations alongside tradi
tional metrics such as PSNR and SSIM provide comprehensive evidence of the
 practical effectiveness of our deblurring technique. Our results indicate that the
proposed method not only excels in quantitative measures but also significantly
 enhances perceptual image quality, making it highly suitable for real-world appli
cations. The source code and results are available at https://github.com/Dip-to/
 Vision-Transformer-and-FFT-ReLU-Fusion-for-Advanced-Image-Deblurring.git</p>
        <p><a href="https://assets-eu.researchsquare.com/files/rs-5306286/v1_covered_ceb4375f-2ef3-4b63-a2c3-deff379f6934.pdf?c=1730021499" target="_blank">Download Preprint</a></p>
        <br>



</div>

</body>
</html> 
